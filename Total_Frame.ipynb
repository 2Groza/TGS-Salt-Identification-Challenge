{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hao/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras import optimizers\n",
    "import keras.layers.advanced_activations\n",
    "import scipy\n",
    "import random\n",
    "import matplotlib.pyplot as plt  \n",
    "from scipy.stats import norm  \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.initializers import VarianceScaling,RandomNormal\n",
    "from keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, concatenate, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import UpSampling2D, Reshape, Lambda, Flatten, Activation,Concatenate\n",
    "from keras.models import Model  \n",
    "from keras.optimizers import SGD, Adadelta, Adagrad,Adam\n",
    "from keras import backend as K  \n",
    "from keras import objectives  \n",
    "from keras.utils.vis_utils import plot_model  \n",
    "from keras.utils import np_utils, generic_utils\n",
    "import sys \n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import sklearn\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import NullFormatter\n",
    "%matplotlib inline\n",
    "from sklearn import manifold, datasets,cluster\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.listdir('/home/hao/DATAS/Salt/train/images')\n",
    "train_image = []\n",
    "train_mask = []\n",
    "for i in range(len(path)):\n",
    "    path_now = path[i]\n",
    "    a = Image.open('/home/hao/DATAS/Salt/train/images/'+str(path_now))\n",
    "    a = np.asarray(a)\n",
    "    train_image.append(a)\n",
    "    b = Image.open('/home/hao/DATAS/Salt/train/masks/'+str(path_now))\n",
    "    b = np.asarray(b)\n",
    "    train_mask.append(b)\n",
    "train_image = np.asarray(train_image)\n",
    "train_mask = np.asarray(train_mask)\n",
    "\n",
    "train_image = train_image/np.max(train_image)\n",
    "train_mask = train_mask/np.max(train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = os.listdir('/home/hao/DATAS/Salt/test/images')\n",
    "test_image = []\n",
    "for i in range(len(path_test)):\n",
    "    path_now = path_test[i]\n",
    "    c = Image.open('/home/hao/DATAS/Salt/test/images/' + str(path_now))\n",
    "    c = np.asarray(c)\n",
    "    test_image.append(c)\n",
    "test_image = np.asarray(test_image)\n",
    "test_image = test_image/np.max(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101)\n",
      "(4000, 101, 101, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_mask.shape)\n",
    "print(train_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =20\n",
    "latent_dim = 256\n",
    "nb_epoch = 50\n",
    "intermediate_dim =256\n",
    "original_dim = 96*96\n",
    "LRelu = 'relu'\n",
    "\n",
    "#USE = 'autoencoder'\n",
    "#USE = 'vae'\n",
    "#encoder:\n",
    "\n",
    "input_img = Input(shape=(96,96,3))\n",
    "\n",
    "conv_1 = Conv2D(20, (3, 3), padding='same',kernel_initializer='normal',dilation_rate=2)(input_img)\n",
    "conv_1 = Activation('relu')(conv_1)\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "maxpool_1 = MaxPooling2D((2, 2),padding='same')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(20, (3, 3), padding='same',kernel_initializer='normal',dilation_rate=2)(maxpool_1)\n",
    "conv_2 = Activation('relu')(conv_2)\n",
    "conv_2 = BatchNormalization()(conv_2)\n",
    "maxpool_2 = MaxPooling2D((2, 2),  padding='same')(conv_2)\n",
    "\n",
    "conv_3 = Conv2D(20, (3, 3),padding='same',kernel_initializer='normal',dilation_rate=1)(maxpool_2)\n",
    "conv_3 = Activation(LRelu)(conv_3)\n",
    "conv_3 = BatchNormalization()(conv_3)\n",
    "maxpool_3 = MaxPooling2D((2, 2),  padding='same')(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(20, (3, 3),padding='same',kernel_initializer='normal',dilation_rate=1)(maxpool_3)\n",
    "conv_4 = Activation(LRelu)(conv_4)\n",
    "conv_4 = BatchNormalization()(conv_4)\n",
    "maxpool_4 = MaxPooling2D((2, 2),  padding='same')(conv_4)\n",
    "\n",
    "conv_5 = Conv2D(20, (3, 3), activation='relu', padding='same',kernel_initializer='normal')(maxpool_4)\n",
    "maxpool_5 = MaxPooling2D((2, 2),  padding='same')(conv_5)\n",
    "\n",
    "\n",
    "#x = Conv2D(5, (3, 3), activation='relu', padding='same',kernel_initializer='normal')(x)\n",
    "#x = MaxPooling2D((2, 2),  padding='same')(x)\n",
    "\n",
    "visual = Flatten()(maxpool_5)\n",
    "h_1 = Dense(intermediate_dim, activation='relu')(visual)#relu?\n",
    "encoded = Dense(latent_dim, activation='tanh')(h_1)# relu?\n",
    "\n",
    "\n",
    "h_3 = Dense(intermediate_dim,activation=LRelu)(encoded)#for AE\n",
    "\n",
    "h_4 = Dense(20*3*3,activation=LRelu)(h_3)\n",
    "h_5 = Reshape((3,3,20))(h_4)\n",
    "\n",
    "\n",
    "conv_6 = Conv2D(20, (3, 3), activation='relu', padding='same',kernel_initializer='normal')(h_5)\n",
    "upsample_6 = UpSampling2D((2, 2))(conv_6)\n",
    "\n",
    "upsample_7 = Concatenate()([upsample_6,conv_5])\n",
    "conv_7 = Conv2D(10, (3, 3), activation='relu', padding='same',kernel_initializer='normal')(upsample_6)\n",
    "upsample_7 = UpSampling2D((2, 2))(conv_7)\n",
    "\n",
    "upsample_7 = Concatenate()([upsample_7,conv_4])\n",
    "conv_8 = Conv2D(10, (3, 3), activation='relu', padding='same',kernel_initializer='normal')(upsample_7)\n",
    "upsample_8 = UpSampling2D((2, 2))(conv_8)\n",
    "\n",
    "upsample_8 = Concatenate()([upsample_8,conv_3])\n",
    "conv_9 = Conv2D(10, (3, 3), activation='relu', padding='same',kernel_initializer='normal')(upsample_8)\n",
    "upsample_9 = UpSampling2D((2, 2))(conv_9)\n",
    "\n",
    "#upsample_9 = Concatenate()([upsample_9,conv_2])\n",
    "conv_10 = Conv2D(5,  (3, 3), activation='relu',padding='same',kernel_initializer='normal')(upsample_9)\n",
    "upsample_10 = UpSampling2D((2, 2))(conv_10)\n",
    "\n",
    "#upsample_10 = Concatenate()([upsample_10,conv_1])\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(upsample_10)\n",
    "\n",
    "\n",
    "EarlyStopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=7, verbose=0, mode='auto')\n",
    "checkpoint = ModelCheckpoint('.h5',monitor ='val_loss',verbose = 1,save_best_only = True)\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1e-6) / (K.sum(K.square(y_true_f)) + K.sum(K.square(y_pred_f)) + 1e-6)\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "#def ae_loss(x, decoded):  \n",
    "#    xent_loss = original_dim * objectives.mean_squared_error(x,decoded)\n",
    "#    return xent_loss\n",
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "autoencoder = Model(inputs=input_img, outputs=decoded)\n",
    "autoencoder.compile(optimizer=adam, loss=dice_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CheckPoint = keras.callbacks.ModelCheckpoint(\"Model_keras.h5\", monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "autoencoder.fit(train_image_96, train_mask_96,\n",
    "        shuffle=True,\n",
    "        epochs=50,\n",
    "        batch_size=5,\n",
    "        validation_split = 0.1,callbacks=[EarlyStopping,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights('.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = autoencoder.predict(test_image[:,5:,5:,:])\n",
    "test_pred_zeroone = np.round(test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug101(test_pred_now):\n",
    "    up = test_pred_now[:5,:,0]\n",
    "    half = np.vstack((up,test_pred_now[:,:,0]))\n",
    "    left = half[:,:5]\n",
    "    final = np.hstack((left,half))\n",
    "    final = np.reshape(final,[101,101,1])\n",
    "    return final\n",
    "\n",
    "def to_line(pic):\n",
    "    line = []\n",
    "    if len(np.shape(pic))==3:\n",
    "        pic = pic[:,:,0]\n",
    "    for i in range(101):\n",
    "        for j in range(101):\n",
    "            line.append(pic[j,i])\n",
    "    return line\n",
    "\n",
    "def to_final_result(line):\n",
    "    i = 1\n",
    "    starts = []\n",
    "    lenths = []\n",
    "    while i<=len(line):\n",
    "        j = 0\n",
    "        if line[i-1] == 1:\n",
    "            starts.append(i)\n",
    "            j = 1\n",
    "            if i<len(line):\n",
    "                while line[i-1+j]==1:\n",
    "                    j+=1\n",
    "                    if i-1+j>= len(line):\n",
    "                        break\n",
    "            lenths.append(j)\n",
    "        i += j+1\n",
    "    comma_split = []\n",
    "    for i in range(len(starts)):\n",
    "        comma_split.append(starts.pop(0))\n",
    "        comma_split.append(lenths.pop(0))\n",
    "    return comma_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_zeroone_101 = []\n",
    "for i in range(len(test_pred_zeroone)):\n",
    "    test_pred_zeroone_101.append(aug101(test_pred_zeroone[i]))\n",
    "test_pred_zeroone_101 = np.asarray(test_pred_zeroone_101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for i in range(18000):\n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "    temp = test_pred_zeroone_101[i]\n",
    "    l = to_final_result(to_line(temp))\n",
    "    k = (\" \".join(str(i) for i in l))\n",
    "    output.append((path_test[i][:-4],k))\n",
    "output = np.asarray(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('output2.txt',output ,fmt = '%s',delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
